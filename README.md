
# TIEâ€“Dialog Pilot Replication

**Goal:** Provide a clean, one-command pipeline to reproduce the key results of the *Humanâ€“Machine Coherence* pilot:
- Coherence curves (ð’žâ‚œ) for human vs. model
- Event detection (peaks/valleys) with Â±1â€¦Â±3 windows
- DTW alignment metrics (`r_warped`, normalized distance, lag)
- Agreement metrics (F1, Cohenâ€™s Îº, Fleiss/Light Îº)
- Figures and an auto-generated PDF report

> Last updated: 2025-11-02

---

## 1) Quickstart

```bash
# Option A â€” Conda
conda env create -f environment.yml
conda activate tie-dialog-pilot

# Option B â€” Pip
python -m venv .venv && source .venv/bin/activate  # (Windows: .venv\Scripts\activate)
pip install -r requirements.txt

# Run the full pipeline with the sample data
make all
# or
python scripts/run_pipeline.py --config configs/config.sample.yml
```

Artifacts will be saved under `reports/` and `reports/figures/`.

---

## 2) Repository layout

```
.
â”œâ”€â”€ CITATION.cff
â”œâ”€â”€ LICENSE
â”œâ”€â”€ Makefile
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ environment.yml
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ config.sample.yml
â”‚   â””â”€â”€ thresholds.example.yml
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ external/        # third-party raw data (not versioned)
â”‚   â”œâ”€â”€ interim/         # intermediate data
â”‚   â”œâ”€â”€ processed/       # final processed datasets
â”‚   â””â”€â”€ raw/             # original CSVs (humans & model)
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ HOWTO.md
â”‚   â””â”€â”€ METHODS.md
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ run_pipeline.py
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ tie_dialog/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ config.py
â”‚   â”‚   â”œâ”€â”€ logging_setup.py
â”‚   â”‚   â”œâ”€â”€ data_loading.py
â”‚   â”‚   â”œâ”€â”€ preprocessing.py
â”‚   â”‚   â”œâ”€â”€ coherence.py
â”‚   â”‚   â”œâ”€â”€ events.py
â”‚   â”‚   â”œâ”€â”€ metrics.py
â”‚   â”‚   â”œâ”€â”€ dtw_analysis.py
â”‚   â”‚   â”œâ”€â”€ plots.py
â”‚   â”‚   â””â”€â”€ report.py
â”‚   â””â”€â”€ tests/
â”‚       â”œâ”€â”€ test_metrics.py
â”‚       â””â”€â”€ test_events.py
â””â”€â”€ reports/
    â”œâ”€â”€ figures/
    â”œâ”€â”€ artifacts/
    â””â”€â”€ README.md
```

---

## 3) Data expected

Place your CSVs in `data/raw/`. Minimum expected files:

- `ct_series.sample.csv` â€” time series with columns:
  - `dialogue_id`, `turn`, `human_ct`, `model_ct`  (ð’žâ‚œ values)
- `events_template.sample.csv` â€” event annotations:
  - `dialogue_id`, `turn`, `human_peak`, `human_valley`, `machine_peak`, `machine_valley` (0/1 flags)

> You can replace the sample files with the actual data, keeping headers.

---

## 4) Configuration

Edit `configs/config.sample.yml` (or copy to `configs/config.yml`) to change windows, thresholds and files.

Key params:
- `windows: [1,2,3]` â€” evaluation windows Â±k
- `peak_prominence`, `valley_prominence` â€” detection parameters
- `smoothing` â€” rolling window etc.
- paths under `data:` and `reports:`

---

## 5) Reproducible pipeline

- Deterministic seeds & versions logged
- All params stored in YAML and exported with artifacts
- One command (`make all`) regenerates figures & report

---

## 6) Citing

See `CITATION.cff`. 

---

## 7) License

MIT (see `LICENSE`)
